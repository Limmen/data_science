{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Simple App - Testing the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some simple computational graphs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow constants take no input and outputs the constant value they store, they are initialized automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_4:0\", shape=(), dtype=float32) Tensor(\"Const_5:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, dtype=tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "print(node1, node2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constants are initialized automatically but the computational graphs are not evaluated automatically, for evaluating we need to create a Session object and run it, we can run multiple computational graphs at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining graphs/tensors together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3: Tensor(\"Add_2:0\", shape=(), dtype=float32)\n",
      "sess.run(node3): 7.0\n"
     ]
    }
   ],
   "source": [
    "node3 = tf.add(node1, node2)\n",
    "print(\"node3:\", node3)\n",
    "print(\"sess.run(node3):\", sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With SummaryWriter's we can write the output graph to a directory which then can be read and visualized by tensorboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "source": [
    "writer = tf.summary.FileWriter(\"output\", sess.graph)\n",
    "print(sess.run(node3))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start tensorboard to visualize the computational graph with the following command: `tensorboard --logdir=output/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualized graph:\n",
    "\n",
    "![Node3 Computational Graph](images/node3-graph.png)\n",
    "\n",
    "Notice that operations are nodes too.\n",
    "\n",
    "The graph above is constant it will always be the same thing, to make things more useful and interesting we use parameterize our model/graphs by using **placeholders**, a placeholder is basically a promise that later a value will be provided. When creating graphs with placeholders it is a bit like a lambda which later gets evaluated with some input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # + provides a shortcut for tf.add(a, b)\n",
    "print(sess.run(adder_node, {a: 3, b: 4.5}))\n",
    "print(sess.run(adder_node, {a: [1, 3], b: [2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've seen constants and placeholders, placeholders allow us to  parameterize our graph. For machine learning we typically require variables that can be modified and updated, not just constants, for example the bias and weights in a neural network would be variables. Tensorflow api conviniently calls these variables for simply \"variables\".\n",
    "\n",
    "As mentioned earlier constants are initialized automatically and their values can never change but for variables we **must manually initialize them**, to initialize **all** variables we can use the following operation (must run it in a session for it to take action):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python got a construct called \"with xx as xx: statement\" which is similar to a try-finally, python will automatically call the __exit__method of the object called with on, so instead of having to use sess.close() we can use with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The run operation of session takes the following inputs (all but one argument are optional):\n",
    "\n",
    "- fetches: The computational graph, kan också vara en lista av graphs, isåfall returneras en lista av värden\n",
    "- feed_dict=None: Input values, (en pyton dict, i.e map), key kan vara en tensor eller en placeholder exemepelvis.\n",
    "- options=None: Extra options, ex sätta på tracing\n",
    "- run_metadata=None: Extra metadata\n",
    "\n",
    "I exemplet nedan så kör vi vår computation graph `linear_model` och  ger den input värde för placeholdern `x`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(linear_model, {x: [1, 2, 3, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu har vi en väldigt simpel linjär model med 2 variabler: W och b, men vi vet inte hur bra vår modell är, vi måste evaluera den så vi använder ytterligare en placeholder `y` för att kunna parameterisera modellen med \"desired value\", i.e label. Denna label kan sedan användas för att beräkna loss exempelvis genom sum of squared loss. \n",
    "\n",
    "** Glöm inte att initialisera variabler, alltid! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notera att i exemplet ovan så är W och b variabler men vi gör ingen träning whatsoever så vi får ingen optimal resultat, vi kan assigna variablerna manuellt för att få optimalt resultat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    fixW = tf.assign(W, [-1.])\n",
    "    fixb = tf.assign(b, [1.])\n",
    "    sess.run([fixW, fixb])\n",
    "    print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning\n",
    "\n",
    "Poängen med machine learning är ju att maskinen själv ska hitta de optimala värdena, inte att vi ska behöva assigna dem. Enter, **training**:\n",
    "\n",
    "Innan vi inspekterar hög-nivå API för tensorflow modeller och training som kallas **estimators** kan vi kolla på ett mer låg-nivå API: **optimizers**\n",
    "\n",
    "Optimizers minimiserar loss-funktion genom att gradvis förändra variablernas värden i modellen, exempelvis kan optimizern använda sig av gradient descent algoritmen (backprop).\n",
    "\n",
    "Det är väldigt enkelt att applicera en optimizer som finns färdigimplementerad i tensorflow om du redan har din computational graph med inkluderade variabler färdig.\n",
    "\n",
    "Notera att du måste själva bestämma hur länge träningen ska pågå, i.e när du nå konvergens, eller om du helt enkelt använder ett fixed antal iterationer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = optimizer.minimize(loss)\n",
    "    sess.run(init) # reset values to incorrect defaults.\n",
    "    for i in range(1000):\n",
    "          sess.run(train, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n",
    "    print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! ovan är exempel på simpel machine learning, där maskinen lär sig parametrarna W och b för att minimisera error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators\n",
    "\n",
    "Estimators är ett hög-nivå API i tensorflow för att skapa machine learning modeller och computational graphs. \n",
    "\n",
    "Estimators har en del inbyggda implementationer som kan användas direkt, ex LinearRegressor etc, men du kan även skapa dina egna custom estimators.\n",
    "\n",
    "Estimators är typiskt parameteriserade med funktioner kallade `input_fn`, ex input till estimator.train är en funktion, input till estimator.evaluate är en funktion, etc.\n",
    "\n",
    "Estimators låter dig även skapa custom modeller, där du själv definierar modellen genom en `model_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
